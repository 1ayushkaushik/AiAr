# -*- coding: utf-8 -*-
"""AiArS1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SFesfwysC3E-__c0AV_KV0prDuRaGPmb
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer()

with open('Data.txt', 'r') as texti:
         textlines=texti.readlines()
          tokenizer.fit_on_texts([textlines])

len(tokenizer.word_index)

input_sequences = []
for sentence in textlines:
  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]


  for i in range(1,len(tokenized_sentence)):
    input_sequences.append(tokenized_sentence[:i+1])

max_len = max([len(x) for x in input_sequences])
print(max_len)

from tensorflow.keras.preprocessing.sequence import pad_sequences
padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')

X = padded_input_sequences[:,:-1]
y = padded_input_sequences[:,-1]

from tensorflow.keras.utils import to_categorical
y = to_categorical(y,num_classes=1183)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

model = Sequential()
model.add(Embedding(1183, 100, input_length=230))
model.add(LSTM(150))
model.add(Dense(1183, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])

model.summary()

model.fit(X,y,epochs=100)

!pip install gradio
import gradio as gr
import numpy as np
import time

# Function to generate text
def generate_text(text, final_key):
    # Tokenize and pad the input text
    token_text = tokenizer.texts_to_sequences([text])[0]
    padded_token_text = pad_sequences([token_text], maxlen=230, padding='pre')

    generated_text = text
    for i in range(final_key):
        # Predict the next word
        pos = np.argmax(model.predict(padded_token_text))

        # Convert the predicted position to word
        for word, index in tokenizer.word_index.items():
            if index == pos:
                generated_text += " " + word
                break

        # Update the input text for the next iteration
        token_text = tokenizer.texts_to_sequences([generated_text])[0]
        padded_token_text = pad_sequences([token_text], maxlen=230, padding='pre')

        # Print the generated text (optional)
        print(generated_text)
        time.sleep(2)

    return generated_text

# Create a Gradio interface
iface = gr.Interface(
    fn=generate_text,
    inputs=["text", "number"],  # Text input and final key as number input
    outputs="text",  # Output is generated text
    title="Text Generation Interface",
    description="Generate text based on the input text and final key."
)

# Launch the interface
iface.launch()

